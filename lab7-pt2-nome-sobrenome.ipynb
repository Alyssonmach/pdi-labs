{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner-pdi](https://user-images.githubusercontent.com/58775072/141189378-b5df3287-e8c0-48a1-ad11-825ba317463b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universidade Federal de Campina Grande (UFCG)\n",
    "## Centro de Engenharia Elétrica e Informática (CEEI) \n",
    "## Disciplina: Int. ao Processamento de Imagem Digital e Visão Computacional\n",
    "## Professora: Luciana Ribeiro Veloso\n",
    "## Aluno(a): Coloque seu nome aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações\n",
    "***\n",
    "\n",
    "1. Os arquivos de laboratório devem ser salvos seguindo o seguinte padrão: `lab-x-nome-sobrenome.ipynb`.\n",
    "2. Não esqueça de colocar o seu nome no cabeçalho acima.\n",
    "3. Não altere a ordem das células e realize as implementações somente nos campos específicados.  \n",
    "4. Ao longo do laboratório será solicitado perguntas teóricas relativas aos assuntos das aulas da disciplina e implementações de código utilizando a linguagem de programação Python. \n",
    "5. As células de implementação com código serão indicadas pelos seguintes comentários: `# IMPLEMENTE O SEU CÓDIGO AQUI`.\n",
    "6. Para editar uma célula de texto, basta clicar duas vezes com o cursos do mouse para editar, e `Ctrl + Enter` para finalizar a edição. \n",
    "7. Para rodar as células com os códigos desenvolvidos, digite `Ctrl + Enter` ou clique em `Run` no menu do Jupyter.\n",
    "8. Dúvidas, problemas de execução de código ou dificuldades com a linguagem de programação Python devem ser feitas durante as aulas de laboratório, encaminhadas para o grupo de WhatsApp da turma ou fórum do PVAE da disciplina.\n",
    "9. Os laboratórios devem ser enviados nos campos especificados pelo PVAE. ATENTE-SE AOS PRAZOS DE ENTREGA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Laboratório 7.2: Classificação de Dígitos com Redes Neurais Artificiais</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                             # operational system para manipulação de arquivos.\n",
    "import cv2                                            # opencv para manipulação de imagens.\n",
    "import random                                         # trabalhar com aleatoriedade\n",
    "import numpy as np                                    # numpy para manipulação de matrizes e arrays.\n",
    "import matplotlib.pyplot as plt                       # pyplot para plotagem de gráficos e imagens.\n",
    "from sklearn.model_selection import train_test_split  # função para particionamento dos dados\n",
    "from tensorflow.keras.models import Sequential        # classe de modelos sequenciais para construir as redes neurais.\n",
    "from tensorflow.keras.utils import to_categorical     # função para preprocessamento dos gabaritos.\n",
    "from tensorflow.keras.datasets import mnist           # dataset utilizado nesse experimento.\n",
    "from tensorflow.keras import layers                   # módulo de camadas do keras\n",
    "from tensorflow.keras import callbacks                # módulo de callbacks do keras\n",
    "from tensorflow.keras import optimizers               # módulo de otimizadores do keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banco de Dados\n",
    "\n",
    "* Vamos utilizar o MNIST, outro banco de dados presente no catálogo de datasets do Keras, que é disponibilizado como uma função pronta;\n",
    "\n",
    "* Cada instância do banco de dados corresponde a uma imagem rotulada de um dígito manuscrito;\n",
    "\n",
    "* As imagens do banco de dados são monocromáticas e de dimensões 28 x 28;\n",
    "\n",
    "* Os gabaritos correspondem ao número manuscrito, sendo um inteiro entre 0 e 9;\n",
    "\n",
    "* O banco de dados contém 60.000 imagens para treino e 10.000 imagens para teste;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organização do banco de dados\n",
    "\n",
    "* Como vimos, a primeira dimensão dos arrays do banco de dados é reservada para controlar a amostra e as demais correspondem às demais dimensões do tipo de dados utilizado. \n",
    "\n",
    "* Nesse caso, os nossos dados são imagens monocromáticas (2D), de modo que são organizados em tensores tridimensionais (3D) com formato: **dados.shape = (amostras, altura, largura)**\n",
    "    * O i-ésimo exemplo pode ser acessado a partir de: **exemplo = dados[i]**\n",
    "    * Um pedaço de uma imagem pode ser acessado de forma similar:\n",
    "        * Quadrante superior esquerdo da i-ésima imagem: **quad = dados[i, :14, :14]**\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O banco de dados pode ser carregado utilizando:\n",
    "    * **(train_data, train_targets), (test_data, test_targets) = mnist.load_data()**\n",
    "    * train_data é um tensor com as entradas do conjunto de treino;\n",
    "    * test_data é um tensor com as entradas do conjunto de teste;\n",
    "    * train_targets é um tensor com os gabaritos do conjunto de treino;\n",
    "    * test_targets é um tensor com os gabaritos do conjunto de teste;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhe exemplos aleatórios\n",
    "indices = np.random.randint(0, 60000 - 1, 10)\n",
    "\n",
    "# plots\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 5, figsize=(16, 8))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    \n",
    "    # plota a imagem\n",
    "    axs[i // 5][i % 5].imshow(train_images[idx], vmin = 0, vmax = 255, cmap=\"gray\")\n",
    "    \n",
    "    # adiciona o gabarito como título\n",
    "    axs[i//5][i%5].set_title(\"Gabarito: {}\".format(train_labels[idx]), fontsize = 16)\n",
    "    \n",
    "    # adiciona o shape como subtítulo\n",
    "    axs[i//5][i%5].set_xlabel(\"Shape: {}\".format(train_images[idx].shape), fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento dos dados de entrada\n",
    "\n",
    "* Como estamos utilizando Redes Neurais Convolucionais 2D, precisamos que a entrada seja seja um array tetradimensional (4D), sendo necessário adicionar uma dimensão para os canais.\n",
    "\n",
    "* Para isso, podemos utilizar a função **reshape(shape)** que reorganiza um array para um determinado formato especificado desde que seja possível alocar todos os valores do array original para o novo formato.\n",
    "\n",
    "* Além disso, como em uma imagem todos os pixels são valores entre 0 e 255, podemos pre-processar os dados de entrada a partir de uma simples divisão por 255, que garante que todos os dados estarão entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \n",
    "    # desfaz adiciona uma dimensão para os canais da imagem\n",
    "    data = data.reshape((len(data), 28, 28, 1))\n",
    "    # normaliza os valores ao dividir pelo maior valor possível dentro das imagens.\n",
    "    data = data.astype(\"float32\")/255\n",
    "    return data\n",
    "\n",
    "preprocessed_train_images = preprocess_data(train_images)\n",
    "preprocessed_test_images  = preprocess_data(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 1: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Verifique as dimensões e a faixa de valores dos dados de treino e teste após o pré-processamento. Não é necessário verificar a faixa de valores para cada característica isoladamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionamento dos dados de treino\n",
    "\n",
    "* Agora vamos criar uma partição de validação a partir do conjunto de treino para realizar uma validação cruzada. \n",
    "\n",
    "* Novamente vamos utilizar a função **train_test_split**, que separa dados e os seus respectivos gabaritos segundo uma fração especificada.\n",
    "\n",
    "* Contudo, dessa vez utilizaremos o parâmetro **stratify**, que indica os rótulos associados aos dados fornecidos. Quando esse parâmetro é fornecido a função realiza o particionamento dos dados e mantém a proporção entre exemplos de uma mesma classe com relação aos dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fração escolhida para separar o mesmo número de instâncias do conjunto de testes\n",
    "data_frac = preprocessed_test_images.shape[0] / preprocessed_train_images.shape[0]\n",
    "\n",
    "# criação do conjunto de validação\n",
    "preprocessed_train_images, preprocessed_val_images, train_labels, val_labels = train_test_split(preprocessed_train_images, # dados de treino\n",
    "                                                                                                train_labels,              # gabaritos de treino\n",
    "                                                                                                test_size = data_frac,     # proporção de dados p/ validação\n",
    "                                                                                                stratify = train_labels,   # dados de referência\n",
    "                                                                                                random_state = 42)         # semente de geração\n",
    "\n",
    "print(\"Treino:\", preprocessed_train_images.shape, train_labels.shape)\n",
    "print(\"Validação:\", preprocessed_val_images.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento dos gabaritos\n",
    "\n",
    "* Nesse caso temos um problema multiclasse com 10 classes, sendo elas correspondentes aos números entre 0 e 9. Consequentemente, o modelo produzido terá 10 unidades de saída, uma para cada classe, e utilizará a função de ativação softmax.\n",
    "\n",
    "* Para fornecer esses gabaritos para a rede durante o treinamento é necessário categorizar as saídas, para limitá-las ao intervalo [0, 1]. Para isso vamos utilizar a função to_categorical() disponível no próprio Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_train_labels = to_categorical(train_labels)\n",
    "categorical_val_labels = to_categorical(val_labels)\n",
    "categorical_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o modelo\n",
    "\n",
    "Para construir o modelo usaremos a classe **Sequential**, que possibilita a construção de modelos sequenciais de forma bastante simples.\n",
    "* A construção do modelo é feita a partir do seu instanciamento como objeto da classe seguido de chamadas à função **add()** para adicionar camadas.\n",
    "* Como estamos construindo Redes Neurais Convolucionais, vamos utilizar as camadas **Input**, **Conv2D**, **MaxPooling2D**, **Dropout**, **Flatten** e **Dense**.\n",
    "    * A camada Input cria a entrada da rede com **Input( shape )**\n",
    "        * shape corresponde ao formato do tensor de entrada, no nosso caso será o número de características do nosso banco de dados (28, 28, 1);\n",
    "    * A camada Conv2D pode ser chamada com **Conv2D( num_kernels, kernel_size, activation = 'linear' )**\n",
    "        * num_kernels corresponde ao número de conjuntos de filtros aplicados, determina o número de mapas de características na saída;\n",
    "        * kernel_size é uma tupla (altura, largura) que determina o tamanho dos filtros;\n",
    "        * activation corresponde à função de ativação utilizada na camada;\n",
    "    * A camada MaxPooling2D pode ser chamada com **MaxPooling2D( kernel_size )**\n",
    "        * kernel_size é uma tupla (altura, largura) que determina o tamanho dos filtros;\n",
    "    * A camada Dropout pode ser chamada com **Dropout( drop_chance )**\n",
    "        * drop_chance é um float que determina a chance de dropout na camada;\n",
    "    * A camada Flatten pode ser chamada com **Flatten( )**\n",
    "        * Essa camada \"achata\" os volumes de dados dos tensores de imagens e transforma em um vetor coluna;\n",
    "    * A camada Dense pode ser chamada com **Dense( n_unidades, activation = 'linear' )**\n",
    "        * n_unidades corresponde ao número de neurônios da camada;\n",
    "        * activation corresponde à função de ativação utilizada na camada;\n",
    "        \n",
    "        \n",
    "* Algumas funções de ativação disponíveis são:\n",
    "    * \"linear\"\n",
    "    * \"relu\"\n",
    "    * \"sigmoid\"\n",
    "    * \"softmax\"\n",
    "    * \"tanh\"\n",
    "\n",
    "\n",
    "* Mais informações sobre a camada dense podem ser vistas em **https://keras.io/api/layers/core_layers/dense/**\n",
    "* Mais informações sobre as ativações disponíveis podem ser vistas em **https://keras.io/api/layers/activations/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 2: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* (a) A função abaixo constroi um modelo de rede neural e utiliza a função summary() para apresentar um resumo das informações da rede neural produzida. Comente o que faz cada linha do código.\n",
    "* (b) (obrigatório) Modifique parâmetros como o número de filtros de cada camada e/ou o formato do tensor de entrada e/ou o número de saídas.\n",
    "* (c) Explique como o número de parâmetros de cada camada é calculado. Esse valor depende do tamanho das imagens de entrada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMENTE AS LINHAS DE CÓDIGO E MODOFIQUE OS PARÂMETROS AQUI --> QUESTÃO 2 - letra (a, b)\n",
    "def build_model( input_shape, n_outputs ):\n",
    "    ''''construindo o modelo baseado em redes neurais convolucionais'''\n",
    "     \n",
    "    rede = Sequential()\n",
    "    rede.add(layers.Input((input_shape)))\n",
    "    rede.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    rede.add(layers.MaxPooling2D(pool_size=(2, 2))) \n",
    "    rede.add(layers.Dropout(rate=0.30))\n",
    "    rede.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    rede.add(layers.MaxPooling2D(pool_size=(2, 2)))  \n",
    "    rede.add(layers.Dropout(rate=0.25))\n",
    "    rede.add(layers.Flatten())\n",
    "    rede.add(layers.Dense(units=128, activation=\"relu\"))\n",
    "    rede.add(layers.Dense(units=n_outputs, activation = \"softmax\"))\n",
    "    \n",
    "    return rede\n",
    "\n",
    "model = build_model( (28, 28, 1), 10 )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Resposta da Questão 2:</span>\n",
    "\n",
    "* (c) Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model((28, 28, 1), 10)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate = 1e-3), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "* Dessa vez utilizaremos uma das callbacks do Keras, o Model_Checkpoint.\n",
    "* Essa função salva o modelo conforme o treinamento é executado à medida que os valores da variável monitorada melhoram, preservando sempre o modelo com os melhores valores obtidos.\n",
    "* model_checkpoint = ModelCheckpoint( path, monitor = None, save_best_only = True, verbose = 1)\n",
    "    * path é o caminho para o salvamento do modelo;\n",
    "    * monitor é a variável que deve ser monitorada pelo callback;\n",
    "    * save_best_only indica se só o melhor modelo deve ser salvo ou se todos os aumentos devem ser salvos;\n",
    "    * verbose é o modo de texto, 1 indica para que o Keras avise quando um novo modelo for salvo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = callbacks.ModelCheckpoint(\"model.hdf5\", monitor = \"val_acc\", save_best_only = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Treinando o modelo\n",
    "\n",
    "O treinamento é realizado a partir da função **fit**, que recebe dados de treino e de validação além de hiperparâmetros como o número de épocas e o tamanho dos lotes de dados (batchsize).\n",
    "\n",
    "* **hist = model.fit( x = None, y = None, epochs = 1, batchsize = None, callbacks = [], validation_data = None, verbose = \"auto\")**\n",
    "    * x corresponde aos dados de treino;\n",
    "    * y corresponde aos gabaritos de treino;\n",
    "    * epochs corresponde ao número de épocas de treinamento;\n",
    "    * batchsize corresponde ao tamanho dos lotes entregues à rede de cada vez;\n",
    "    * callbacks corresponde à lista de callbacks utilizada;\n",
    "    * validation_data corresponde a uma tupla ( val_data, val_targets ) com os dados de validação;\n",
    "    * verbose indica como a função deve reportar os resultados:\n",
    "        * 0: modo silencioso, nenhum retorno em formato de texto;\n",
    "        * 1: retorno a cada época e barra de progresso;\n",
    "        * 2: retorno a cada época sem barra de progresso;\n",
    "    * hist é um dicionário de retorno com os valores de loss e das métricas computadas para treino e validação;\n",
    "    \n",
    "    \n",
    "    \n",
    "* Lista de callbacks disponíveis: https://keras.io/api/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(preprocessed_train_images, categorical_train_labels, \n",
    "                    epochs=10, batch_size=128, callbacks = [model_checkpoint], \n",
    "                    validation_data = (preprocessed_val_images, categorical_val_labels))\n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotagens Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, squeeze = False, figsize = (16,8))\n",
    "\n",
    "# Loss\n",
    "train_loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "# Epochs\n",
    "epochs = range(1, len(train_loss_values) + 1)\n",
    "\n",
    "# Accuracy\n",
    "train_acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "ax = axes.flat[0]\n",
    "ax.plot(epochs, train_loss_values, 'r', label='Training loss')\n",
    "ax.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "ax.set_title('Training and validation Loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes.flat[1]\n",
    "ax.plot(epochs, train_acc_values, 'r', label='Training acc')\n",
    "ax.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "ax.set_title('Training and validation Accuracy')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes com o Modelo\n",
    "\n",
    "O teste do modelo pode ser realizado a partir da função **evaluate**, que recebe os dados de treino e retorna o valor de loss calculado para esse conjunto e os valores de cada métrica da lista fornecida durante a compilação do modelo. \n",
    "\n",
    "* É uma prática comum realizar ajustes no modelo com base no conjunto de validação e só utilizar o conjunto de testes após a definição dos hiperparâmetros definitivos.\n",
    "* Como os hiperparâmetros são ajustados a partir dos resultados obtidos para o conjunto de validação, o modelo pode acabar. sobreajustando aos dados de validação, então é interessante mudar os dados desse conjunto com frequência.\n",
    "* Para mudar os dados de validação basta alterar a semente na função train_test_split.\n",
    "* Crie um novo modelo do zero após a realização de mudanças nos conjuntos de treino/validação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 3: [Valor da Questão: 4.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* (a) As Redes Convolucionais obtiveram melhores resultados que as Redes Neurais Artificiais nesse banco de dados? \n",
    "* (b) Alguma das Redes Neurais Artificiais produzidas na parte 1 obtiveram resultados comparáveis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(preprocessed_test_images, categorical_test_labels)\n",
    "\n",
    "print(\"Test Accuracy:\", 100*test_acc, \"%\")\n",
    "print(\"Acertos: {} - Erros: {}\".format(round(len(preprocessed_test_images)*test_acc), \n",
    "                                       round(len(preprocessed_test_images)*(1-test_acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.hdf5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(preprocessed_test_images, categorical_test_labels)\n",
    "\n",
    "print(\"Test Accuracy:\", 100*test_acc, \"%\")\n",
    "print(\"Acertos: {} - Erros: {}\".format(round(len(preprocessed_test_images)*test_acc), \n",
    "                                       round(len(preprocessed_test_images)*(1-test_acc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 3:</span>\n",
    "\n",
    "* (a) Adicione sua resposta aqui.\n",
    "* (b) Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(xtest, ytest, ypred, num = 25, tipo = \"rand\"):\n",
    "    \n",
    "    if tipo == \"acertos\":\n",
    "        fltr_idx = [i for i in range(xtest.shape[0]) if ypred[i] == ytest[i]]\n",
    "    else:\n",
    "        fltr_idx = [i for i in range(xtest.shape[0]) if ypred[i] != ytest[i]]\n",
    "        \n",
    "    indices = np.random.choice(fltr_idx, min(num, len(fltr_idx)), replace=False)\n",
    "       \n",
    "    rows = int(num/5)\n",
    "    fig, axs = plt.subplots(nrows = rows, ncols = 5, figsize=(20, 4*rows))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = xtest[idx]\n",
    "        if ypred[idx] == ytest[idx]:\n",
    "            axs[i//5][i%5].set_title(str(ytest[idx]), color = \"green\", fontsize = 20)\n",
    "        else:\n",
    "            axs[i//5][i%5].set_title(\"Pred: {} - Gabarito: {}\".format(ypred[idx], ytest[idx]), color = \"red\", fontsize = 20)\n",
    "        \n",
    "        axs[i//5][i%5].imshow(img, vmin=0, vmax=255, cmap = \"gray\")\n",
    "    return\n",
    "\n",
    "pred_labels = model.predict(preprocessed_test_images, verbose=1)\n",
    "preds = np.argmax(pred_labels, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acertos do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(test_images, test_labels, preds, tipo = \"acertos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erros do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(test_images, test_labels, preds, tipo = \"erros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 4: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Existe algum padrão nos gabaritos errados que possam confundir a rede em sua análise? Comente utilizando os exemplos vistos na célula acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Resposta da Questão 4:</span>\n",
    "\n",
    "* Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gif5](https://user-images.githubusercontent.com/58775072/142713072-0a070f19-b8cb-4ee2-92e5-1a3ec8ded6b2.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
