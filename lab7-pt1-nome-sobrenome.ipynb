{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner-pdi](https://user-images.githubusercontent.com/58775072/141189378-b5df3287-e8c0-48a1-ad11-825ba317463b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universidade Federal de Campina Grande (UFCG)\n",
    "## Centro de Engenharia Elétrica e Informática (CEEI) \n",
    "## Disciplina: Int. ao Processamento de Imagem Digital e Visão Computacional\n",
    "## Professora: Luciana Ribeiro Veloso\n",
    "## Aluno(a): Coloque seu nome aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações\n",
    "***\n",
    "\n",
    "1. Os arquivos de laboratório devem ser salvos seguindo o seguinte padrão: `lab-x-nome-sobrenome.ipynb`.\n",
    "2. Não esqueça de colocar o seu nome no cabeçalho acima.\n",
    "3. Não altere a ordem das células e realize as implementações somente nos campos específicados.  \n",
    "4. Ao longo do laboratório será solicitado perguntas teóricas relativas aos assuntos das aulas da disciplina e implementações de código utilizando a linguagem de programação Python. \n",
    "5. As células de implementação com código serão indicadas pelos seguintes comentários: `# IMPLEMENTE O SEU CÓDIGO AQUI`.\n",
    "6. Para editar uma célula de texto, basta clicar duas vezes com o cursos do mouse para editar, e `Ctrl + Enter` para finalizar a edição. \n",
    "7. Para rodar as células com os códigos desenvolvidos, digite `Ctrl + Enter` ou clique em `Run` no menu do Jupyter.\n",
    "8. Dúvidas, problemas de execução de código ou dificuldades com a linguagem de programação Python devem ser feitas durante as aulas de laboratório, encaminhadas para o grupo de WhatsApp da turma ou fórum do PVAE da disciplina.\n",
    "9. Os laboratórios devem ser enviados nos campos especificados pelo PVAE. ATENTE-SE AOS PRAZOS DE ENTREGA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Laboratório 7.1: Classificação de Dígitos com Redes Neurais Artificiais</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os                                              # operational system para manipulação de arquivos.\n",
    "import cv2                                             # openCV para manipulação de imagens.\n",
    "import numpy as np                                     # numpy para manipulação de matrizes e arrays.\n",
    "import matplotlib.pyplot as plt                        # pyplot para plotagem de gráficos e imagens.\n",
    "from sklearn.model_selection import train_test_split   # função para particionamento dos dados\n",
    "from tensorflow.keras.models import Sequential         # classe de modelos sequenciais para construir as redes neurais.\n",
    "from tensorflow.keras.layers import Dense, Input       # camada de neurônios densamente conectados.\n",
    "from tensorflow.keras.optimizers import Adam           # otimizador \"Descida do Gradiente com Momento\".\n",
    "from tensorflow.keras.utils import to_categorical      # função para preprocessamento dos gabaritos.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # callback que salva o modelo durante o treinamento\n",
    "from tensorflow.keras.datasets import mnist            # dataset utilizado nesse experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banco de Dados\n",
    "\n",
    "* Vamos utilizar o MNIST, outro banco de dados presente no catálogo de datasets do Keras, que é disponibilizado como uma função pronta;\n",
    "\n",
    "* Cada instância do banco de dados corresponde a uma imagem rotulada de um dígito manuscrito;\n",
    "\n",
    "* As imagens do banco de dados são monocromáticas e de dimensões 28 x 28;\n",
    "\n",
    "* Os gabaritos correspondem ao número manuscrito, sendo um inteiro entre 0 e 9;\n",
    "\n",
    "* O banco de dados contém 60.000 imagens para treino e 10.000 imagens para teste;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organização do banco de dados\n",
    "\n",
    "* Como vimos, a primeira dimensão dos arrays do banco de dados é reservada para controlar a amostra e as demais correspondem às demais dimensões do tipo de dados utilizado. \n",
    "\n",
    "* Nesse caso, os nossos dados são imagens monocromáticas (2D), de modo que são organizados em tensores tridimensionais (3D) com formato: **dados.shape = (amostras, altura, largura)**\n",
    "    * O i-ésimo exemplo pode ser acessado a partir de: **exemplo = dados[i]**\n",
    "    * Um pedaço de uma imagem pode ser acessado de forma similar:\n",
    "        * Quadrante superior esquerdo da i-ésima imagem: **quad = dados[i, :14, :14]**\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O banco de dados pode ser carregado utilizando:\n",
    "    * **(train_data, train_targets), (test_data, test_targets) = mnist.load_data()**\n",
    "    * train_data é um tensor com as entradas do conjunto de treino;\n",
    "    * test_data é um tensor com as entradas do conjunto de teste;\n",
    "    * train_targets é um tensor com os gabaritos do conjunto de treino;\n",
    "    * test_targets é um tensor com os gabaritos do conjunto de teste;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 1: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* O código abaixo plota alguns exemplos aleatórios do banco de dados e verifica algumas das suas propriedades.\n",
    "    * (a) Verifique alguns exemplos do banco de dados e suas propriedades.\n",
    "    * (b) O quão semelhantes as amostras de um mesmo dígito são entre si?\n",
    "    * (c) Os gabaritos estão sempre de acordo com as imagens?\n",
    "    * (d) Desenvolver um algoritmo baseado em PDI para classificar esses dígitos seria uma tarefa simples? Quais seriam as principais dificuldades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhe exemplos aleatórios\n",
    "indices = np.random.randint(0, 60000 - 1, 10)\n",
    "\n",
    "# plots\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 5, figsize=(16, 8))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    \n",
    "    # plota a imagem\n",
    "    axs[i // 5][i % 5].imshow( train_images[idx], vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "    \n",
    "    # adiciona o gabarito como título\n",
    "    axs[i // 5][i % 5].set_title( \"Gabarito: {}\".format(train_labels[idx]), fontsize = 16)\n",
    "    \n",
    "    # adiciona o shape como subtítulo\n",
    "    axs[i // 5][i % 5].set_xlabel( \"Shape: {}\".format(train_images[idx].shape), fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 1:</span>\n",
    "\n",
    "* (a) Adicione sua reposta aqui.  \n",
    "* (b) Adicione sua reposta aqui. \n",
    "* (c) Adicione sua reposta aqui. \n",
    "* (d) Adicione sua reposta aqui. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 2: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Utilize a função np.unique() para verificar os possíveis gabaritos em train_labels e test_labels.\n",
    "\n",
    "    * https://numpy.org/doc/stable/reference/generated/numpy.unique.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento dos dados de entrada\n",
    "\n",
    "* Como estamos utilizando Redes Neurais Artificiais não podemos utilizar as imagens em formato de matriz, precisamos que a entrada seja seja um vetor de características.\n",
    "\n",
    "* Para isso, podemos utilizar a função **reshape(shape)** que reorganiza um array para um determinado formato especificado desde que seja possível alocar todos os valores do array original para o novo formato.\n",
    "\n",
    "* Além disso, como em uma imagem todos os pixels são valores entre 0 e 255, podemos pre-processar os dados de entrada a partir de uma simples divisão por 255, que garante que todos os dados estarão entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \n",
    "    # desfaz a matriz da imagem e reorganiza os dados como um vetor\n",
    "    data = data.reshape((len(data), 28 * 28))\n",
    "    # normaliza os valores ao dividir pelo maior valor possível dentro das imagens.\n",
    "    data = data.astype(\"float32\") / 255\n",
    "    return data\n",
    "\n",
    "train_vectors = preprocess_data(train_images)\n",
    "test_vectors  = preprocess_data(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 3: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Verifique as dimensões e a faixa de valores dos dados de treino e teste após o pré-processamento. Não é necessário verificar a faixa de valores para cada característica isoladamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionamento dos dados de treino\n",
    "\n",
    "* Agora vamos criar uma partição de validação a partir do conjunto de treino para realizar uma validação cruzada. \n",
    "\n",
    "* Novamente vamos utilizar a função **train_test_split**, que separa dados e os seus respectivos gabaritos segundo uma fração especificada.\n",
    "\n",
    "* Contudo, dessa vez utilizaremos o parâmetro **stratify**, que indica os rótulos associados aos dados fornecidos. Quando esse parâmetro é fornecido a função realiza o particionamento dos dados e mantém a proporção entre exemplos de uma mesma classe com relação aos dados originais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 4: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* O código abaixo mostra a distribuição dos dados em um conjunto de gabaritos. Comente o que cada linha do programa faz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMENTE AS LINHAS DE CÓDIGO AQUI --> QUESTÃO 4\n",
    "\n",
    "def print_label_percentage(labels):\n",
    "    \n",
    "    unique, counts = np.unique(labels, return_counts = True)\n",
    "    for u, c in zip(unique, counts):\n",
    "        print( \"\\tGabarito {}: {} ({:.2f}%)\".format( u, c, 100 * c / labels.shape[0]))\n",
    "    return\n",
    "\n",
    "print(\"Treino:\")\n",
    "print_label_percentage(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 5: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* As classes do banco de dados são balanceadas? O train_test_split conseguiu manter as mesmas proporções entre as classes que os dados originais?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fração escolhida para separar o mesmo número de instâncias do conjunto de testes\n",
    "data_frac = test_vectors.shape[0] / train_vectors.shape[0]\n",
    "\n",
    "# criação do conjunto de validação\n",
    "train_vectors, val_vectors, train_labels, val_labels = train_test_split(train_vectors,           # dados de treino\n",
    "                                                                        train_labels,            # gabaritos de treino\n",
    "                                                                        test_size = data_frac,   # proporção de dados p/ validação\n",
    "                                                                        stratify = train_labels, # dados de referência\n",
    "                                                                        random_state = 42)        # semente de geração\n",
    "\n",
    "print(\"Treino:\", train_vectors.shape, train_labels.shape)\n",
    "print_label_percentage( train_labels )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Validação:\", val_vectors.shape, val_labels.shape)\n",
    "print_label_percentage( val_labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Resposta da Questão 5:</span>\n",
    "\n",
    "* Adicione sua reposta aqui.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento dos gabaritos\n",
    "\n",
    "* Nesse caso temos um problema multiclasse com 10 classes, sendo elas correspondentes aos números entre 0 e 9. Consequentemente, o modelo produzido terá 10 unidades de saída, uma para cada classe, e utilizará a função de ativação softmax.\n",
    "\n",
    "* Para fornecer esses gabaritos para a rede durante o treinamento é necessário categorizar as saídas, para limitá-las ao intervalo [0, 1]. Para isso vamos utilizar a função to_categorical() disponível no próprio Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_train_labels = to_categorical(train_labels)\n",
    "categorical_val_labels = to_categorical(val_labels)\n",
    "categorical_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 6: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* O código abaixo mostra alguns exemplos da transformação realizada pela função to_categorical(). Analise os exemplos e explique, o que a função faz?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhe exemplos aleatórios\n",
    "indices = np.random.randint(0, categorical_train_labels.shape[0]-1, 10)\n",
    "\n",
    "# printa exemplos selecionados\n",
    "for i, idx in enumerate(indices):\n",
    "    categorical_example = categorical_train_labels[idx]\n",
    "    non_categorical_example = train_labels[idx]\n",
    "    print(\"{} -> {}\".format(non_categorical_example, categorical_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Resposta da Questão 6:</span>\n",
    "\n",
    "* Adicione sua reposta aqui.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o modelo\n",
    "\n",
    "Para construir o modelo usaremos a classe **Sequential**, que possibilita a construção de modelos sequenciais de forma bastante simples.\n",
    "* A construção do modelo é feita a partir do seu instanciamento como objeto da classe seguido de chamadas à função **add()** para adicionar camadas.\n",
    "* Como estamos construindo apenas Redes Neurais Artificiais por enquanto, vamos utilizar apenas as camadas **Dense** e **Input**.\n",
    "    * A camada Input cria a entrada da rede com **Input( shape )**\n",
    "        * shape corresponde ao formato do tensor de entrada, no nosso caso será o número de características do nosso banco de dados (13);\n",
    "    * A camada Dense pode ser chamada com **Dense( n_unidades, activation = 'linear' )**\n",
    "        * n_unidades corresponde ao número de neurônios da camada;\n",
    "        * activation corresponde à função de ativação utilizada na camada;\n",
    "* Algumas funções de ativação disponíveis são:\n",
    "    * \"linear\"\n",
    "    * \"relu\"\n",
    "    * \"sigmoid\"\n",
    "    * \"softmax\"\n",
    "    * \"tanh\"\n",
    "\n",
    "\n",
    "* Mais informações sobre a camada dense podem ser vistas em **https://keras.io/api/layers/core_layers/dense/**\n",
    "* Mais informações sobre as ativações disponíveis podem ser vistas em **https://keras.io/api/layers/activations/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 7: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Nesse caso utilizamos uma saída com ativação \"softmax\". Por que usamos essa ativação e não algo como a ativação sigmóide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model( n_inputs, n_outputs ):\n",
    "    \n",
    "    rede = Sequential()\n",
    "    rede.add( Input( (n_inputs, ) ) )\n",
    "    rede.add( Dense(  128, activation = \"relu\") )\n",
    "    rede.add( Dense(  256, activation = \"relu\") )\n",
    "    rede.add( Dense( n_outputs, activation = \"softmax\" ) )\n",
    "    return rede\n",
    "\n",
    "model = build_model( 28*28, 10 )\n",
    "model.compile( optimizer = Adam( learning_rate = 5e-4 ), \n",
    "               loss=\"categorical_crossentropy\", \n",
    "               metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dessa vez utilizaremos uma das callbacks do Keras, o Model_Checkpoint.\n",
    "* Essa função salva o modelo conforme o treinamento é executado à medida que os valores da variável monitorada melhoram, preservando sempre o modelo com os melhores valores obtidos.\n",
    "* model_checkpoint = ModelCheckpoint( path, monitor = None, save_best_only = True, verbose = 1)\n",
    "    * path é o caminho para o salvamento do modelo;\n",
    "    * monitor é a variável que deve ser monitorada pelo callback;\n",
    "    * save_best_only indica se só o melhor modelo deve ser salvo ou se todos os aumentos devem ser salvos;\n",
    "    * verbose é o modo de texto, 1 indica para que o Keras avise quando um novo modelo for salvo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\"model.h5\", monitor = \"val_acc\", save_best_only = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Resposta da Questão 7:</span>\n",
    "\n",
    "* Adicione sua reposta aqui.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo\n",
    "\n",
    "O treinamento é realizado a partir da função **fit**, que recebe dados de treino e de validação além de hiperparâmetros como o número de épocas e o tamanho dos lotes de dados (batchsize).\n",
    "\n",
    "* **hist = model.fit( x = None, y = None, epochs = 1, batchsize = None, callbacks = [], validation_data = None, verbose = \"auto\")**\n",
    "    * x corresponde aos dados de treino;\n",
    "    * y corresponde aos gabaritos de treino;\n",
    "    * epochs corresponde ao número de épocas de treinamento;\n",
    "    * batchsize corresponde ao tamanho dos lotes entregues à rede de cada vez;\n",
    "    * callbacks corresponde à lista de callbacks utilizada;\n",
    "    * validation_data corresponde a uma tupla ( val_data, val_targets ) com os dados de validação;\n",
    "    * verbose indica como a função deve reportar os resultados:\n",
    "        * 0: modo silencioso, nenhum retorno em formato de texto;\n",
    "        * 1: retorno a cada época e barra de progresso;\n",
    "        * 2: retorno a cada época sem barra de progresso;\n",
    "    * hist é um dicionário de retorno com os valores de loss e das métricas computadas para treino e validação;\n",
    "    \n",
    "    \n",
    "    \n",
    "* Lista de callbacks disponíveis: https://keras.io/api/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit( train_vectors, categorical_train_labels, epochs = 10, batch_size = 128, callbacks = [model_checkpoint], \n",
    "                    validation_data = (val_vectors, categorical_val_labels))\n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotagens Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, squeeze = False, figsize = (16, 8))\n",
    "\n",
    "# loss\n",
    "train_loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "\n",
    "# epochs\n",
    "epochs = range(1, len(train_loss_values) + 1)\n",
    "\n",
    "# accuracy\n",
    "train_acc_values = history_dict[\"acc\"]\n",
    "val_acc_values = history_dict[\"val_acc\"]\n",
    "\n",
    "ax = axes.flat[0]\n",
    "ax.plot(epochs, train_loss_values, \"r\", label = \"Training loss\")\n",
    "ax.plot(epochs, val_loss_values, \"b\", label = \"Validation loss\")\n",
    "ax.set_title(\"Training and validation Loss\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "\n",
    "ax = axes.flat[1]\n",
    "ax.plot(epochs, train_acc_values, \"r\", label = \"Training acc\")\n",
    "ax.plot(epochs, val_acc_values, \"b\", label = \"Validation acc\")\n",
    "ax.set_title(\"Training and validation Accuracy\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando o Modelo\n",
    "\n",
    "O teste do modelo pode ser realizado a partir da função **evaluate**, que recebe os dados de treino e retorna o valor de loss calculado para esse conjunto e os valores de cada métrica da lista fornecida durante a compilação do modelo. \n",
    "\n",
    "* É uma prática comum realizar ajustes no modelo com base no conjunto de validação e só utilizar o conjunto de testes após a definição dos hiperparâmetros definitivos.\n",
    "* Como os hiperparâmetros são ajustados a partir dos resultados obtidos para o conjunto de validação, o modelo pode acabar. sobreajustando aos dados de validação, então é interessante mudar os dados desse conjunto com frequência.\n",
    "* Para mudar os dados de validação basta alterar a semente na função train_test_split.\n",
    "* Crie um novo modelo do zero após a realização de mudanças nos conjuntos de treino/validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_vectors, categorical_test_labels)\n",
    "\n",
    "print(\"Test Accuracy:\", 100*test_acc, \"%\")\n",
    "print(\"Acertos: {} - Erros: {}\".format(round(len(test_vectors)*test_acc), \n",
    "                                       round(len(test_vectors)*(1-test_acc) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_vectors, categorical_test_labels)\n",
    "\n",
    "print(\"Test Accuracy:\", 100*test_acc, \"%\")\n",
    "print(\"Acertos: {} - Erros: {}\".format(round(len(test_vectors)*test_acc), \n",
    "                                       round(len(test_vectors)*(1-test_acc) )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(xtest, ytest, ypred, num = 25, tipo = \"rand\"):\n",
    "    \n",
    "    if tipo == \"acertos\":\n",
    "        fltr_idx = [i for i in range(xtest.shape[0]) if ypred[i] == ytest[i]]\n",
    "    else:\n",
    "        fltr_idx = [i for i in range(xtest.shape[0]) if ypred[i] != ytest[i]]\n",
    "        \n",
    "    indices = np.random.choice(fltr_idx, min(num, len(fltr_idx)), replace = False)\n",
    "       \n",
    "    rows = int(num / 5)\n",
    "    fig, axs = plt.subplots(nrows = rows, ncols = 5, figsize=(20, 4*rows))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = xtest[idx]\n",
    "        if ypred[idx] == ytest[idx]:\n",
    "            axs[i//5][i%5].set_title(str(ytest[idx]), color = \"green\", fontsize = 20)\n",
    "        else:\n",
    "            axs[i//5][i%5].set_title(\"Pred: {} - Gabarito: {}\".format(ypred[idx], ytest[idx]), color = \"red\", fontsize = 20)\n",
    "        \n",
    "        axs[i//5][i%5].imshow(img, vmin=0, vmax=255, cmap = \"gray\")\n",
    "    return\n",
    "\n",
    "pred_labels = model.predict(test_vectors, verbose = 1)\n",
    "preds = np.argmax(pred_labels, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acertos do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(test_images, test_labels, preds, tipo = \"acertos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erros do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(test_images, test_labels, preds, tipo = \"erros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gif4](https://user-images.githubusercontent.com/58775072/142712884-23841c4b-a01e-4d5b-b64a-5fe0cec5e8e7.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
