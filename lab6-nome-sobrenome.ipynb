{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c324ed59",
   "metadata": {},
   "source": [
    "![banner-pdi](https://user-images.githubusercontent.com/58775072/141189378-b5df3287-e8c0-48a1-ad11-825ba317463b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958ca6e",
   "metadata": {},
   "source": [
    "## Universidade Federal de Campina Grande (UFCG)\n",
    "## Centro de Engenharia Elétrica e Informática (CEEI) \n",
    "## Disciplina: Int. ao Processamento de Imagem Digital e Visão Computacional\n",
    "## Professora: Luciana Ribeiro Veloso\n",
    "## Aluno(a): Coloque seu nome aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188024d",
   "metadata": {},
   "source": [
    "## Observações\n",
    "***\n",
    "\n",
    "1. Os arquivos de laboratório devem ser salvos seguindo o seguinte padrão: `lab-x-nome-sobrenome.ipynb`.\n",
    "2. Não esqueça de colocar o seu nome no cabeçalho acima.\n",
    "3. Não altere a ordem das células e realize as implementações somente nos campos específicados.  \n",
    "4. Ao longo do laboratório será solicitado perguntas teóricas relativas aos assuntos das aulas da disciplina e implementações de código utilizando a linguagem de programação Python. \n",
    "5. As células de implementação com código serão indicadas pelos seguintes comentários: `# IMPLEMENTE O SEU CÓDIGO AQUI`.\n",
    "6. Para editar uma célula de texto, basta clicar duas vezes com o cursos do mouse para editar, e `Ctrl + Enter` para finalizar a edição. \n",
    "7. Para rodar as células com os códigos desenvolvidos, digite `Ctrl + Enter` ou clique em `Run` no menu do Jupyter.\n",
    "8. Dúvidas, problemas de execução de código ou dificuldades com a linguagem de programação Python devem ser feitas durante as aulas de laboratório, encaminhadas para o grupo de WhatsApp da turma ou fórum do PVAE da disciplina.\n",
    "9. Os laboratórios devem ser enviados nos campos especificados pelo PVAE. ATENTE-SE AOS PRAZOS DE ENTREGA!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e50ca2",
   "metadata": {},
   "source": [
    "# <span style='color:red'>Laboratório 6: Redes Neurais Artificiais</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589bb56",
   "metadata": {},
   "source": [
    "### Importação dos Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                                 # operational system para manipulação de arquivos.\n",
    "import cv2                                                # openCV para manipulação de imagens.\n",
    "import numpy as np                                        # numpy para manipulação de matrizes e arrays.\n",
    "import matplotlib.pyplot as plt                           # pyplot para plotagem de gráficos e imagens.\n",
    "from sklearn.model_selection import train_test_split      # função para particionamento dos dados\n",
    "from tensorflow.keras.models import Sequential            # classe de modelos sequenciais para construir as redes neurais.\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout # camada de neurônios densamente conectados.\n",
    "from tensorflow.keras.optimizers import SGD               # otimizador \"Descida do Gradiente com Momento\".\n",
    "from tensorflow.keras.datasets import boston_housing      # dataset utilizado nesse experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ed0c5",
   "metadata": {},
   "source": [
    "### Banco de Dados\n",
    "* Vamos utilizar um banco de dados do catálogo de datasets do Keras, que é disponibilizado como uma função pronta;\n",
    "\n",
    "* Cada instância do banco de dados corresponde a um conjunto de 13 valores referentes a características de subúrbios de Boston na década de 1970, a exemplo de taxa de crimes, imposto sobre propriedade, etc;\n",
    "\n",
    "* Esses valores serão utilizados para calcular o valor mediano das residências no respectivo subúrbio em um problema de regressão, de modo que iremos mapear um vetor de entrada com 13 valores em um vetor de saída com 1 único elemento;\n",
    "\n",
    "* O banco de dados contém 506 valores divididos em 404 instâncias de treino e 102 de teste;\n",
    "\n",
    "* Uma descrição mais detalhada dos valores de entrada pode ser vista em http://lib.stat.cmu.edu/datasets/boston, onde os valores são descritos na ordem que aparecem;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b723a",
   "metadata": {},
   "source": [
    "### Organização do banco de dados\n",
    "\n",
    "* Comumente os dados utilizados no treinamento de modelos de inteligência artificial reservam a primeira dimensão para controlar a amostra e espalham o tipo de dado utilizado nas demais dimensões do tensor. \n",
    "\n",
    "\n",
    "* Nesse caso, os nossos dados são vetores de características unidimensionais (1D), de modo que são organizados em tensores bidimensionais (2D) com formato: **dados.shape = (amostras, características)**\n",
    "    * O i-ésimo exemplo pode ser acessado a partir de: **exemplo = dados[i]**\n",
    "    * A j-ésima característica dos exemplos pode ser acessada a partir de: **caracteristica = dados[:, j]**\n",
    "    * Porções do tensor podem ser acessadas utilizando fatiamento, por exemplo:\n",
    "        * primeiros_5_exemplos = dados[:5]\n",
    "        * caracteristicas_9a13 = dados[8:13]\n",
    "        \n",
    "\n",
    "* Lembrem-se que a contagem de índices em Python começa em 0 e só é inclusiva no primeiro elemento:\n",
    "    * **:5** produz os índices **0, 1, 2, 3, 4** \n",
    "    * **8:13** produz os índices **8, 9, 10, 11, 12** \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51653c3",
   "metadata": {},
   "source": [
    "* O banco de dados pode ser carregado utilizando:\n",
    "    * **(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()**\n",
    "    * train_data é um tensor com as entradas do conjunto de treino;\n",
    "    * test_data é um tensor com as entradas do conjunto de teste;\n",
    "    * train_targets é um tensor com os gabaritos do conjunto de treino;\n",
    "    * test_targets é um tensor com os gabaritos do conjunto de teste;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721c22e",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 1: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* (a) O código abaixo carrega o banco de dados, acesse alguns exemplos de treinamento e de teste e veja suas dimensões.\n",
    "    * Use índices entre **[0, 404]** para os dados de treino e entre **[0, 102]** para os de teste.\n",
    "\n",
    "* (b) Verifique as dimensões e as faixas de valores de cada característica nos vetores de entrada dos conjuntos de treino e de teste. A faixa de valores das características são semelhantes? E os dados de treino e de teste?**</span>\n",
    "    * Encontre os valores mínimo/máximo além da média **(np.mean)** e da variância **(np.var)** de cada uma das 13 características.\n",
    "    * Sugestão: leia sobre o parâmetro \"axis\" na documentação das funções **np.min**, **np.max** e **np.mean**.\n",
    "* (c) Verifique as dimensões e as faixas de valores dos gabaritos dos conjuntos de treino e de teste. Os valores encontrados são semelhantes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8882dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 1 - letra (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf65e85",
   "metadata": {},
   "source": [
    "|**Características dos Dados de Entrada**|**Descrição**|\n",
    "|:-:|:-|\n",
    "|**CRIM**|     <span style='color:red'>per capita crime rate by town</span>|\n",
    "|**ZN**|       <span style='color:red'>proportion of residential land zoned for lots over 25,000 sq.ft.</span>|\n",
    "|**INDUS**|    <span style='color:red'>proportion of non-retail business acres per town</span>|\n",
    "|**CHAS**|     <span style='color:red'>Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</span>|\n",
    "|**NOX**|      <span style='color:red'>nitric oxides concentration (parts per 10 million)</span>|\n",
    "|**RM**|       <span style='color:red'>average number of rooms per dwelling</span>|\n",
    "|**AGE**|      <span style='color:red'>proportion of owner-occupied units built prior to 1940</span>|\n",
    "|**DIS**|      <span style='color:red'>weighted distances to five Boston employment centres</span>|\n",
    "|**RAD**|      <span style='color:red'>index of accessibility to radial highways</span>|\n",
    "|**TAX**|      <span style='color:red'>full-value property-tax rate per \\$10,000</span>|\n",
    "|**PTRATIO**|  <span style='color:red'>pupil-teacher ratio by town</span>|\n",
    "|**B**|        <span style='color:red'>$1000(B_k - 0.63)^2$ where Bk is the proportion of blacks by town</span>|\n",
    "|**LSTAT**|    <span style='color:red'>\\% lower status of the population</span>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a04c7",
   "metadata": {},
   "source": [
    "|**Características dos Dados de Saída**|**Descrição**|\n",
    "|:-:|:-|\n",
    "|**MEDV**|     <span style='color:red'>Median value of owner-occupied homes in \\$1000's</span>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 1 - letra (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cffae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI -QUESTÃO 1 - letra (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867bb2f1",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 1:</span>\n",
    "\n",
    "* (a) Adicione suas respostas aqui.\n",
    "* (b) Adicione suas respostas aqui.\n",
    "* (c) Adicione suas respostas aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96da0af",
   "metadata": {},
   "source": [
    "### Pre-processamento dos dados\n",
    "\n",
    "* Dados cujas características assumem diferentes faixas de valores muitas vezes são problemáticos para o aprendizado dos modelos e podem reduzir a velocidade de convergência ou até mesmo limitar as capacidades do modelo final.\n",
    "\n",
    "* Nesse sentido, uma prática comum é a normalização dos dados antes do treinamento, que geralmente é feito por característica em forma da subtração da média e divisão pelo desvio padrão, o que faz com que os dados resultantes tenham média 0 e variância 1.\n",
    "\n",
    "* Um ponto muito importante é que a normalização deve ser feita partir dos mesmos valores em todos os conjuntos, ou seja, os dados são normalizados segundo informações do conjunto de treino.\n",
    "\n",
    "* Na prática não temos como calcular a média e variância real, mas se os dados de treino são significativos os seus valores são suficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a média do conjunto de treino\n",
    "mean = train_data.mean(axis = 0)\n",
    "# Calcula o desvio padrão do conjunto de treino\n",
    "std = train_data.std(axis = 0)\n",
    "# Normaliza os dados de treino\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "# Normaliza os dados de teste\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072889a2",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 2: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Repita o item b da primeira questão para os dados normalizados. O que se observa quantos aos valores de média e variância para os dados de treino e teste? Comente a sua interpretação sobre as diferenças observadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e56306",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Resposta da Questão 2:</span>\n",
    "\n",
    "* Adicione suas respostas aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32a400e",
   "metadata": {},
   "source": [
    "Agora vamos criar uma partição de validação a partir do conjunto de treino para realizar uma validação cruzada. Vamos utilizar a função **train_test_split**, que separa dados e os seus respectivos gabaritos segundo uma fração especificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fração escolhida para separar o mesmo número de instâncias do conjunto de testes\n",
    "data_frac = test_data.shape[0] / train_data.shape[0]\n",
    "\n",
    "# criação do conjunto de validação\n",
    "train_data, val_data, train_targets, val_targets = train_test_split(train_data,             # dados de treino\n",
    "                                                                    train_targets,          # gabaritos de treino\n",
    "                                                                    test_size = data_frac,  # proporção de dados p/ validação\n",
    "                                                                    random_state = 42)      # semente de geração\n",
    "\n",
    "print(\"Treino:\", train_data.shape, train_targets.shape)\n",
    "print(\"Validação:\", val_data.shape, val_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d99618",
   "metadata": {},
   "source": [
    "### Construindo o modelo\n",
    "\n",
    "Para construir o modelo usaremos a classe **Sequential**, que possibilita a construção de modelos sequenciais de forma bastante simples.\n",
    "* A construção do modelo é feita a partir do seu instanciamento como objeto da classe seguido de chamadas à função **add()** para adicionar camadas.\n",
    "* Como estamos construindo apenas Redes Neurais Artificiais por enquanto, vamos utilizar apenas as camadas **Dense** e **Input**.\n",
    "    * A camada Input cria a entrada da rede com **Input(shape = None )**\n",
    "        * shape corresponde ao formato do tensor de entrada, no nosso caso será o número de características do nosso banco de dados (13);\n",
    "    * A camada Dense pode ser chamada com **Dense(n_unidades, activation = 'linear' )**\n",
    "        * n_unidades corresponde ao número de neurônios da camada;\n",
    "        * activation corresponde à função de ativação utilizada na camada;\n",
    "* Algumas funções de ativação disponíveis são:\n",
    "    * \"linear\"\n",
    "    * \"relu\"\n",
    "    * \"sigmoid\"\n",
    "    * \"softmax\"\n",
    "    * \"tanh\"\n",
    "\n",
    "\n",
    "* Mais informações sobre a camada dense podem ser vistas em **https://keras.io/api/layers/core_layers/dense/**\n",
    "* Mais informações sobre as ativações disponíveis podem ser vistas em **https://keras.io/api/layers/activations/**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00974f4a",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 3: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* (a) A função abaixo constroi um modelo de rede neural e utiliza a função summary() para apresentar um resumo das informações da rede neural produzida. Comente o que faz cada linha do código.\n",
    "    * (opcional) Modifique parâmetros como o número de unidades de cada camada e/ou o formato do tensor de entrada e/ou o número de saídas.\n",
    "* (b) Explique como o número de parâmetros de cada camada é calculado.\n",
    "* (c) Nesse caso utilizamos uma saída com ativação linear. Qual seria a desvantagem de utilizar esse tipo de ativação nas demais camadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMENTE AS LINHAS DE CÓDIGO AQUI --> QUESTÃO 3 -letra (a)\n",
    "def build_model( n_inputs, n_outputs ):\n",
    "    '''construção do modelo de rede neural convolucional'''\n",
    "    \n",
    "    rede = Sequential()\n",
    "    rede.add( Dense(units = 64, activation = \"relu\", input_shape = (n_inputs,)))\n",
    "    rede.add(Dense(units = 64, activation = \"relu\"))\n",
    "    rede.add(Dense(units = n_outputs ))\n",
    "    return rede\n",
    "\n",
    "model = build_model(13, 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4981fdfe",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 3:</span>\n",
    "\n",
    "* (b) Adicione suas respostas aqui.\n",
    "* (c) Adicione suas respostas aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777b774",
   "metadata": {},
   "source": [
    "Após a construção do modelo ele deve ser compilado antes que os parâmetros sejam treinados. Isso é feito utilizando a função **compile**:\n",
    "\n",
    "* **model.compile( optimizer = opt, loss = fperdas, metrics = [] )** \n",
    "    * O optimizer é o algoritmo otimizador utilizado no lugar da descida do gradiente, o Keras oferece diversas opções;\n",
    "        * Para treinar a partir da descida do gradiente utilizaremos o SGD (descida do gradiente com momento), mas setaremos esse parâmetro para 0.\n",
    "        * **opt = SGD( learning_rate = taxa_de_aprendizagem, momentum = 0 )**\n",
    "    * A função de perdas pode ser definida a partir do parâmetro loss, como este é um problema de regressão utilizaremos o erro médio quadrático: \n",
    "        * **loss = \"mse\"**\n",
    "    * Podemos passar uma lista de métricas a serem computadas durante o treinamento, nesse caso utilizaremos o erro médio absoluto:\n",
    "        * **metrics = [\"mae\"]**\n",
    "        * Note que estamos passando uma lista com uma única métrica, mas outras poderiam ser adicionadas à lista.\n",
    "         \n",
    "         \n",
    "\n",
    "* Algoritmos otimizadores populares são o Adam (**https://keras.io/api/optimizers/adam/**) e o RMSprop(**https://keras.io/api/optimizers/rmsprop/**)\n",
    "* Mais informações sobre os otimizadores disponíveis podem ser vistas em **https://keras.io/api/optimizers/**\n",
    "* Mais informações sobre as funções de perdas disponíveis podem ser vistas em **https://keras.io/api/losses/**\n",
    "* Mais informações sobre as métricas disponíveis podem ser vistas em **https://keras.io/api/metrics/**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(13, 1)\n",
    "model.compile( optimizer = SGD(learning_rate = 0.001, momentum = 0.0), loss = \"mse\", metrics = [\"mae\"] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d8f73",
   "metadata": {},
   "source": [
    "### Treinando o modelo\n",
    "\n",
    "O treinamento é realizado a partir da função **fit**, que recebe dados de treino e de validação além de hiperparâmetros como o número de épocas e o tamanho dos lotes de dados (batchsize).\n",
    "\n",
    "* **hist = model.fit(x = None, y = None, epochs = 1, batchsize = None, validation_data = None, verbose = \"auto\")**\n",
    "    * x corresponde aos dados de treino;\n",
    "    * y corresponde aos gabaritos de treino;\n",
    "    * epochs corresponde ao número de épocas de treinamento;\n",
    "    * batchsize corresponde ao tamanho dos lotes entregues à rede de cada vez;\n",
    "    * validation_data corresponde a uma tupla ( val_data, val_targets ) com os dados de validação;\n",
    "    * verbose indica como a função deve reportar os resultados:\n",
    "        * 0: modo silencioso, nenhum retorno em formato de texto;\n",
    "        * 1: retorno a cada época e barra de progresso;\n",
    "        * 2: retorno a cada época sem barra de progresso;\n",
    "    * hist é um dicionário de retorno com os valores de loss e das métricas computadas para treino e validação;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca33af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x = train_data, y = train_targets, epochs = 100, \n",
    "                 batch_size = 1, validation_data = ( val_data, val_targets ), \n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56764543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando os resultados obtidos\n",
    "fig, axes = plt.subplots(1, 2, squeeze = False, figsize = (16,8))\n",
    "\n",
    "history_dict = hist.history\n",
    "\n",
    "# loss - MSE\n",
    "train_loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "\n",
    "# epochs\n",
    "epochs = range(1, len(train_loss_values) + 1)\n",
    "\n",
    "# metrica - MAE\n",
    "train_mae_values = history_dict[\"mae\"]\n",
    "val_mae_values = history_dict[\"val_mae\"]\n",
    "\n",
    "ax = axes.flat[0]\n",
    "ax.plot(epochs, train_loss_values, \"r\", label = \"Training MSE\")\n",
    "ax.plot(epochs, val_loss_values, \"b\", label = \"Validation MSE\")\n",
    "ax.set_title(\"Training and Validation MSE\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.legend()\n",
    "\n",
    "ax = axes.flat[1]\n",
    "ax.plot(epochs, train_mae_values, \"r\", label = \"Training MAE\")\n",
    "ax.plot(epochs, val_mae_values, \"b\", label = \"Validation MAE\")\n",
    "ax.set_title(\"Training and Validation MAE\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"MAE\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a07ea",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 4: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Comente os resultados obtidos nos gráficos acima. Houve overfitting? Se sim, o que pode ser feito para melhorar a qualidade do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f6b2e",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 4:</span>\n",
    "\n",
    "* Adicione suas respostas aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201551d",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 5: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Modifique hiperparâmetros do modelo como o número de camadas, as funções de ativação, o número de épocas utilizadas e o tamanho dos lotes. Comente os resultados obtidos a partir das mudanças realizadas. Utilize várias células para dividir as etapas de construção dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62038b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEUS MODELOS AQUI --> QUESTÃO 5 (use várias células)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18b32c",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 5:</span>\n",
    "\n",
    "* Adicione suas respostas aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a7e7e",
   "metadata": {},
   "source": [
    "### Teste do modelo\n",
    "\n",
    "O teste do modelo pode ser realizado a partir da função **evaluate**, que recebe os dados de treino e retorna o valor de loss calculado para esse conjunto e os valores de cada métrica da lista fornecida durante a compilação do modelo. \n",
    "\n",
    "* É uma prática comum realizar ajustes no modelo com base no conjunto de validação e só utilizar o conjunto de testes após a definição dos hiperparâmetros definitivos.\n",
    "* Como os hiperparâmetros são ajustados a partir dos resultados obtidos para o conjunto de validação, o modelo pode acabar. sobreajustando aos dados de validação, então é interessante mudar os dados desse conjunto com frequência.\n",
    "* Para mudar os dados de validação basta alterar a semente na função train_test_split.\n",
    "* Crie um novo modelo do zero após a realização de mudanças nos conjuntos de treino/validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de924836",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse, test_mae = model.evaluate( test_data, test_targets)\n",
    "\n",
    "# observa-se que os dados de saída são normalizados em milhares de dólares, \n",
    "# então é necessário multiplicar por 1000 para obter os valores absolutos\n",
    "print(\"Erro médio absoluto de teste: ${:.2f}\".format(1000*test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28da1d1",
   "metadata": {},
   "source": [
    "## <span style='color:blue'>Questão 6: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    "\n",
    "* Verifique novamente a faixa de valores dos gabaritos no banco de dados. Considerando a extensão dessa faixa de valores, pode-se dizer que as predições do modelo são significativas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b6806",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Resposta da Questão 6:</span>\n",
    "\n",
    "* Adicione suas respostas aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8646d",
   "metadata": {},
   "source": [
    "### Referências\n",
    "* Chollet, Francois. Deep learning with Python. Simon and Schuster, 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d87de",
   "metadata": {},
   "source": [
    "***\n",
    "![image](https://user-images.githubusercontent.com/58775072/156389663-fcacd20e-8479-4596-b7c4-c438f39424b8.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
