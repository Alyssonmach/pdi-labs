{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6143670b",
   "metadata": {},
   "source": [
    "![banner-pdi](https://user-images.githubusercontent.com/58775072/141189378-b5df3287-e8c0-48a1-ad11-825ba317463b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5eba9",
   "metadata": {},
   "source": [
    "## Universidade Federal de Campina Grande (UFCG)\n",
    "## Centro de Engenharia Elétrica e Informática (CEEI) \n",
    "## Disciplina: Int. ao Processamento de Imagem Digital e Visão Computacional\n",
    "## Professora: Luciana Ribeiro Veloso\n",
    "## Aluno(a): Coloque seu nome aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee31d0",
   "metadata": {},
   "source": [
    "## Observações\n",
    "***\n",
    "\n",
    "1. Os arquivos de laboratório devem ser salvos seguindo o seguinte padrão: `lab-x-nome-sobrenome.ipynb`.\n",
    "2. Não esqueça de colocar o seu nome no cabeçalho acima.\n",
    "3. Não altere a ordem das células e realize as implementações somente nos campos específicados.  \n",
    "4. Ao longo do laboratório será solicitado perguntas teóricas relativas aos assuntos das aulas da disciplina e implementações de código utilizando a linguagem de programação Python. \n",
    "5. As células de implementação com código serão indicadas pelos seguintes comentários: `# IMPLEMENTE O SEU CÓDIGO AQUI`.\n",
    "6. Para editar uma célula de texto, basta clicar duas vezes com o cursos do mouse para editar, e `Ctrl + Enter` para finalizar a edição. \n",
    "7. Para rodar as células com os códigos desenvolvidos, digite `Ctrl + Enter` ou clique em `Run` no menu do Jupyter.\n",
    "8. Dúvidas, problemas de execução de código ou dificuldades com a linguagem de programação Python devem ser feitas durante as aulas de laboratório, encaminhadas para o grupo de WhatsApp da turma ou fórum do PVAE da disciplina.\n",
    "9. Os laboratórios devem ser enviados nos campos especificados pelo PVAE. ATENTE-SE AOS PRAZOS DE ENTREGA!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0ca0b1",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Laboratório 5.2: Segmentação em Imagens</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9238d",
   "metadata": {},
   "source": [
    "### Importação dos Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a61713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                    # operational system para manipulação de arquivos\n",
    "import cv2                                   # opencv para manipulação de imagens\n",
    "import numpy as np                           # numpy para manipulação de matrizes e arrays\n",
    "import urllib.request as url                 # urllib para baixar arquivos via HTTPS\n",
    "import zipfile                               # zipfile para lidar com arquivos compactados\n",
    "import matplotlib.pyplot as plt              # pyplot para plotagem de gráficos e imagens\n",
    "import matplotlib.patheffects as PathEffects # função utilitária de plotagem gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixando as imagens de referência\n",
    "url.urlretrieve('https://github.com/Alyssonmach/pdi-labs/raw/main/imagens.zip', 'imagens.zip')\n",
    "with zipfile.ZipFile('imagens.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16abbd69",
   "metadata": {},
   "source": [
    "### Transformada de Hough\n",
    "\n",
    "A biblioteca OpenCV disponibiliza funções para a aplicação da Transformada de Hough, viabilizando a identificação de retas e círculos:\n",
    "\n",
    "1. Detecção de Linhas:  \n",
    "    * **lines = cv2.HoughLines(src_img, $\\rho_{res}$, $\\theta_{res}$, threshold)**\n",
    "    * **src_img** é a imagem de entrada e deve ser uma imagem binária;\n",
    "    * $\\rho_{res}$ controla a sensibilidade da variável $\\rho$, em unidades;\n",
    "    * $\\theta_{res}$ controla a sensibilidade da variável $\\theta$, em radianos;\n",
    "    * **threshold** é o limiar do acumulador para que uma linha seja considerada válida;\n",
    "    * **lines** é um array que armazena as linhas;\n",
    "        * A variável tem dimensões (L, 1, 2), sendo L o número de linhas detectadas\n",
    "        * Cada linha tem dimensões (1, 2) -> [$\\rho$, $\\theta$]\n",
    "        * A i-ésima linha é acessada por linha = lines[ i ]  \n",
    "        \n",
    "2. Detecção de Círculos:\n",
    "    * **circles = cv2.HoughCircles(src_img, cv2.HOUGH_GRADIENT, dp, dist, param1, param2, minRadius=0, maxRadius=0)**\n",
    "    * **src_img** é a imagem de entrada;\n",
    "    * **cv2.HOUGH_GRADIENT** é um flag que determina o método a ser utilizado pelo algoritmo;\n",
    "    * **dp** controla a resolução da matriz de acumuladores;\n",
    "    * **dist** controla a distância mínima entre círculos para suprimir múltiplas detecção de um mesmo objeto;\n",
    "    * **param1** representa o limiar superior de um detector de Canny aplicado internamente à função, o limiar inferior é escolhido como param1/2;\n",
    "    * **param2** é uma variável análoga ao threshold de cv2.HoughLines e controla o limiar do acumulador para os círculos;\n",
    "    * **minRadius** e **maxRadius** controlam os valores mínimo e máximo do raio dos círculos detectados. São ignorados se deixados no valor default 0.\n",
    "    * **circles** é um array que armazena os círculos;\n",
    "        * A variável tem dimensões **(C, 3)**, sendo C o número de círculos detectados\n",
    "        * Cada círculo de raio r e centrado em **(x1, y1)** tem dimensões (3) -> [x1, y1, r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb5b91",
   "metadata": {},
   "source": [
    "As funções a seguir podem ser utilizadas para desenhar linhas e círculos detectados:      \n",
    "\n",
    "* **cv2.line(dst_img, (x1,y1), (x2,y2), color, width)**\n",
    "* **cv2.circle(dst_img, (cx, cy), r, color, width)**\n",
    "    * **dst_img** é a imagem de saída onde o desenho será feito;\n",
    "    * **(x1, y1)** e **(x2, y2)** representam pontos do início/fim da linha desenhada;\n",
    "    * **(cx, cy)** e **r** representam as coordenadas do centro do círculo e o raio, respectivamente;\n",
    "    * **color** é uma tupla rgb (vermelho, verde, azul) que indica a cor da linha/circulo desenhado;\n",
    "    * **width** indica a largura das linhas. Pode ser -1 no caso do circulo, indicando que a forma deve ser preenchida;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ed1a8",
   "metadata": {},
   "source": [
    " ## <span style='color:blue'>Questão 1: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "* O código abaixo realiza a detecção de linhas da imagem **Fig1034(a)(marion_airport).tif** utilizando a transformada de Hough. O que representam os pontos (x0, y0) marcados em ciano?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f718aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê imagem e converte para escala de cinza\n",
    "rgb_img = cv2.imread(\"imagens/Fig1034(a)(marion_airport).tif\") [:, :, ::-1]\n",
    "src_img = cv2.cvtColor( rgb_img, cv2.COLOR_RGB2GRAY )\n",
    "\n",
    "# Realiza detecção de bordas\n",
    "canny_output = cv2.Canny(image = src_img, threshold1 = 100, threshold2 = 200, L2gradient = True )\n",
    "\n",
    "# Realiza detecção de linhas\n",
    "lines = cv2.HoughLines(image = canny_output,  rho = 1 ,  theta = 1 * np.pi / 180 , threshold = 200)\n",
    "\n",
    "# Desenha as linhas em uma cópia de rgb_img\n",
    "dst_img = rgb_img.copy()\n",
    "\n",
    "for line in lines:\n",
    "    rho   = line[0][0]\n",
    "    theta = line[0][1]\n",
    "    \n",
    "    # Linhas\n",
    "    x1 = int(rho * np.cos(theta) - 1000 * np.sin(theta))\n",
    "    y1 = int(rho * np.sin(theta) + 1000 * np.cos(theta))\n",
    "    x2 = int(rho * np.cos(theta) + 1000 * np.sin(theta))\n",
    "    y2 = int(rho * np.sin(theta) - 1000 * np.cos(theta))\n",
    "    cv2.line(img = dst_img, pt1 = (x1,y1), pt2 = (x2,y2), color = (255, 0, 0), thickness = 2)\n",
    "\n",
    "    # Pontos\n",
    "    x0 = int(rho * np.cos(theta))\n",
    "    y0 = int(rho * np.sin(theta))\n",
    "    cv2.circle(img = dst_img, center = (x0, y0), radius = 5, color = (0, 255, 255), thickness = -1)\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 3, figsize=(16, 24))\n",
    "    \n",
    "# Imagem Original\n",
    "axs[0].imshow(src_img, cmap=\"gray\")\n",
    "axs[0].set_title(\"Original\", fontsize = 16)\n",
    "\n",
    "# Filtragem\n",
    "axs[1].imshow(canny_output, vmin = 0, vmax = 255, cmap=\"gray\")\n",
    "axs[1].set_title(\"Detector de Canny\", fontsize = 16)\n",
    "\n",
    "# Filtragem\n",
    "axs[2].imshow(dst_img, vmin = 0, vmax = 255)\n",
    "axs[2].set_title(\"Detecção de Linhas\", fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add7939",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 1:</span>\n",
    "\n",
    "* Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7a947",
   "metadata": {},
   "source": [
    " ## <span style='color:blue'>Questão 2: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    " \n",
    "* O código abaixo utiliza a transformada de Hough para circular todos os planetas em um desenho do nosso Sistema Solar. Modifique os parâmetros da função cv2.HoughCircles e tente circular os planetas individualmente. Comente os resultados observados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e631ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circles(src_img, circles_array, color = (255, 0, 0), width = 1):\n",
    "    '''Desenha círculos detectadas pela transformada de Hough'''\n",
    "        \n",
    "    dst_img = src_img.copy()\n",
    "    circles_array = np.uint16(np.around(circles_array))\n",
    "    for circle in circles_array[0]:\n",
    "        x1, y1, r = circle\n",
    "        # Circunferência\n",
    "        cv2.circle(dst_img, (x1, y1), r, color, width)\n",
    "        # Centro\n",
    "        cv2.circle(dst_img, (x1, y1), 10, (255, 0, 255), -1)\n",
    "        \n",
    "    return dst_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ef2c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lê imagem e converte para escala de cinza\n",
    "bgr_img = cv2.imread(\"imagens/planets.jpg\") [:, :, ::-1]\n",
    "src_img = cv2.cvtColor( bgr_img, cv2.COLOR_RGB2GRAY )\n",
    "\n",
    "# detectando todos os planetas\n",
    "circles = cv2.HoughCircles(src_img,cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=50, minRadius=15, maxRadius=150)\n",
    "dst_img = draw_circles(bgr_img, circles, color = (255, 0, 0), width = 5)\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 3, figsize=(16, 24))\n",
    "    \n",
    "# Imagem Original\n",
    "axs[0].imshow(bgr_img, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[0].set_title(\"Original\", fontsize = 16)\n",
    "\n",
    "# Filtragem\n",
    "axs[1].imshow(src_img, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[1].set_title(\"Escala de Cinza\", fontsize = 16)\n",
    "\n",
    "# Filtragem\n",
    "axs[2].imshow(dst_img, vmin = 0, vmax = 255)\n",
    "axs[2].set_title(\"Detecção de Círculos\", fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI -> QUESTÃO 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c315f8",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 2:</span>\n",
    "\n",
    "* Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758487b",
   "metadata": {},
   "source": [
    "### Segmentação por Limiarização\n",
    "A biblioteca OpenCV disponibiliza funções para a limiarização de imagens:\n",
    "\n",
    "1. Limiarização com limiar global:  \n",
    "    * **limiar, th1 = cv2.threshold( src_img, limiar, vmax, cv2.THRESH_BINARY )**\n",
    "2. Limiarização com limiar global escolhido automaticamente:\n",
    "    * **limiar, th1 = cv2.threshold( src_img, 0, vmax, cv2.THRESH_BINARY + cv2.THRESH_OTSU )**\n",
    "3. Limiarização com limiar local escolhido automaticamente:\n",
    "    * **th1 = cv2.adaptiveThreshold(src_img, vmax, flag, cv2.THRESH_BINARY, block_size, C)**\n",
    "    \n",
    "As variáveis listadas correspondem a:\n",
    "* **src_img** é a imagem de entrada;\n",
    "* **limiar** é o valor global de limiarização;\n",
    "* **vmax** é o valor para o qual os pixels acima do limiar são setados;\n",
    "* **cv2.THRESH_BINARY** é um flag que indica o tipo de limiarização a ser executado. Outras opções estão disponíveis;\n",
    "* **block_size** define o tamanho da janela utilizada na limiarização adaptativa;\n",
    "* **C** é uma constante que controla a definição do limiar local;\n",
    "* **flag** define a forma como o limiar local é definido:\n",
    "    * Se for **cv2.ADAPTIVE_THRESH_MEAN_C** o limiar local é definido como a média da vizinhança menos C\n",
    "    * Se for **cv2.ADAPTIVE_THRESH_GAUSSIAN_C** o limiar local é definido como uma soma ponderada gaussiana da vizinhança menos C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac73e72",
   "metadata": {},
   "source": [
    " ## <span style='color:blue'>Questão 3: [Valor da Questão: 1.0][Taxa de acerto: x.x]</span>\n",
    "* O código abaixo realiza a segmentação de um marca-passo a partir de uma imagem de raio-x. Analise o código e comente sobre os passos executados nesse processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_img = cv2.imread(\"imagens/pacemaker.png\", 0 )\n",
    "hist = cv2.calcHist([src_img], [0], None, [256], [0,256])\n",
    "    \n",
    "_, th1 = cv2.threshold(src_img, 15, 255, cv2.THRESH_BINARY)\n",
    "_, th2 = cv2.threshold(src_img, 85, 255, cv2.THRESH_BINARY)\n",
    "_, th3 = cv2.threshold(src_img, 195, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "th4 = cv2.erode(th3, kernel, iterations = 4)\n",
    "th4 = cv2.dilate(th4, kernel, iterations = 5)\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(16, 10))\n",
    "    \n",
    "# Imagem Original\n",
    "axs[0][0].imshow(src_img, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[0][0].set_title(\"Original\", fontsize = 16)\n",
    "\n",
    "# Histograma\n",
    "axs[0][1].plot(hist)\n",
    "axs[0][1].set_xlim([0,256])\n",
    "axs[0][1].axvline(x = 15, label = \"15\", c = \"r\", ls = \"--\")\n",
    "axs[0][1].axvline(x = 85, label = \"85\", c = \"g\", ls = \"--\")\n",
    "axs[0][1].axvline(x = 195, label = \"195\", c = \"b\", ls = \"--\")\n",
    "axs[0][1].set_title(\"Histograma\", fontsize = 16)\n",
    "axs[0][1].legend()\n",
    "\n",
    "# Segmentação de Marca-Passo\n",
    "axs[0][2].imshow(th4, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[0][2].set_title(\"Segmentação de Marca-Passo\", fontsize = 16)\n",
    "\n",
    "axs[1][0].imshow(th1, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[1][1].imshow(th2, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[1][2].imshow(th3, vmin = 0, vmax = 255, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c96982",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 3:</span>\n",
    "\n",
    "* Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b32e5",
   "metadata": {},
   "source": [
    " ## <span style='color:blue'>Questão 4: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "* (a) O código abaixo realiza a segmentação de uma imagem utilizando limiarização de Otsu e limiarização Adaptativa. Qual método foi mais bem sucedido? Por que esse método funcionou melhor que os outros?\n",
    "* (b) Em seguida, o próximo código realiza a segmentação de uma imagem utilizando limiarização de Otsu e limiarização Adaptativa. Qual método foi mais bem sucedido? Por que esse método funcionou melhor que os outros?\n",
    "* (c) Qual a função do filtro gaussiano é aplicada antes da limiarização? A sua retirada produz efeitos significativos nas imagens dos itens a e b? Experimente também em outras figuras da pasta de imagens e comente os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÓDIGO DE REFERÊNCIA --> QUESTÃO 4 - letra (a)\n",
    "src_img = cv2.imread(\"imagens/Fig1036(c)(gaussian_noise_mean_0_std_50_added).tif\", 0)\n",
    "src_img = cv2.GaussianBlur(src_img,(5,5),0)\n",
    "hist = cv2.calcHist([src_img], [0], None, [256], [0,256])\n",
    "    \n",
    "limiar, th1 = cv2.threshold(src_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "th2 = cv2.adaptiveThreshold(src_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "th3 = cv2.adaptiveThreshold(src_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 2, figsize = (16, 10))\n",
    "    \n",
    "# Imagem Original\n",
    "axs[0][0].imshow(src_img, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[0][0].set_title(\"Original\", fontsize = 16)\n",
    "\n",
    "axs[0][1].imshow(th1, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[0][1].set_title(\"Otsu\", fontsize = 16)\n",
    "\n",
    "axs[1][0].imshow(th2, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[1][0].set_title(\"ADAPTIVE_THRESH_MEAN_C\", fontsize = 16)\n",
    "\n",
    "axs[1][1].imshow(th3, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[1][1].set_title(\"ADAPTIVE_THRESH_GAUSSIAN_C\", fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÓDIGO DE REFERÊNCIA --> QUESTÃO 4 - letra (b)\n",
    "src_img = cv2.imread( os.path.join(\".\", \"imagens\", \"Fig1049(a)(spot_shaded_text_image).tif\"), 0)\n",
    "src_img = cv2.GaussianBlur(src_img,(5,5),0)\n",
    "hist = cv2.calcHist([src_img], [0], None, [256], [0,256])\n",
    "    \n",
    "limiar, th1 = cv2.threshold( src_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "th2 = cv2.adaptiveThreshold(src_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "th3 = cv2.adaptiveThreshold(src_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 2, figsize = (16, 10))\n",
    "    \n",
    "# Imagem Original\n",
    "axs[0][0].imshow(src_img, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[0][0].set_title(\"Original\", fontsize = 16)\n",
    "\n",
    "axs[0][1].imshow(th1, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[0][1].set_title(\"Otsu\", fontsize = 16)\n",
    "\n",
    "axs[1][0].imshow(th2, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[1][0].set_title(\"ADAPTIVE_THRESH_MEAN_C\", fontsize = 16)\n",
    "\n",
    "axs[1][1].imshow(th3, vmin = 0, vmax = 255, cmap = \"gray\")\n",
    "axs[1][1].set_title(\"ADAPTIVE_THRESH_GAUSSIAN_C\", fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 4 - letra (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7876527",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 4:</span>\n",
    "\n",
    "* (a) Adicione sua resposta aqui.\n",
    "* (b) Adicione sua resposta aqui.\n",
    "* (c) Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e100469",
   "metadata": {},
   "source": [
    "### Segmentação por Cor\n",
    "\n",
    "Utilizando espaço de cores como HSV é possível segmentar imagens a partir das cores de objetos. Nesse contexto, a biblioteca OpenCV disponibiliza funções para a conversão de espaço de cores e para a filtragem das imagens coloridas:\n",
    "\n",
    "1. **Conversão RGB -> HSV**:  \n",
    "    * **hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)**\n",
    "    * O canal **H** corresponde à tonalidade da cor e determina o ângulo no cilindro da figura abaixo. Varia de 0 a 180 sendo cada unidade correspondente a 2 graus no ângulo descrito;\n",
    "    * O canal **S** corresponde à saturação e determina a pureza das cores, quanto menor o valor de S mais diluído em cinza é a tonalidade da cor, determina o raio no cilindro da figura abaixo. Varia de 0 a 255;\n",
    "    * O canal **V** corresponde à intensidade luminosa (ou brilho) e determina a altura no cilindro da figura abaixo. O canal V pode ser pensado como a imagem em escala de cinza. Varia de 0 a 255;\n",
    "2. Seleção de elementos intermediários:\n",
    "    * **mask = cv2.inRange(src_img, lower_bound, higher_bound)**\n",
    "    * **src_img** é a imagem de entrada;\n",
    "    * **lower_bound** é um array que determina limiares inferiores;\n",
    "    * **higher_bound** é um array que determina limiares superiores;\n",
    "    * **mask** é uma imagem binária cujos pixels tem valor alto (255) se os respectivos valores de src_img estão entre os valores de lower_bound e higher_bound para todas as coordenadas;\n",
    "    \n",
    "Observações:\n",
    "\n",
    "* Vermelho se localiza nos arredores de 0 graus.\n",
    "* Amarelo se localiza nos arredores de 60 graus.\n",
    "* Verde se localiza nos arredores de 120 graus.\n",
    "* Ciano se localiza nos arredores de 180 graus.\n",
    "* Azul se localiza nos arredores de 240 graus.\n",
    "* Magenta se localiza nos arredores de 300 graus.\n",
    "* Tons mais específicos podem ser localizados empiricamente.\n",
    "* O valor no OpenCV é o nº de graus dividido por 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2c983",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/58775072/142745820-b48af5ef-d0c0-4b50-b112-0e0dc6705651.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc52e9",
   "metadata": {},
   "source": [
    " ## <span style='color:blue'>Questão 5: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    " \n",
    "* (a) O código abaixo realiza a segmentação de uma maçã na imagem **apple.jpg** a partir da sua cor. Analise o código e comente os resultados produzidos.\n",
    "    * O que acontece se a etapa de erosão for retirada? \n",
    "    * E a etapa de dilatação? \n",
    "* (b) Seria possível realizar um processo semelhante utilizando o espaço RGB?. Quais seriam as principais dificuldades de se utilizar esse espaço de cores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a imagem e converte\n",
    "rgb_img = cv2.imread(\"imagens/apple.jpg\" )[:,:,::-1]\n",
    "hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Filtragem por cor\n",
    "min_HUE =   0; max_HUE = 30\n",
    "min_SAT = 145; max_SAT = 255\n",
    "min_VAL = 135; max_VAL = 255\n",
    "mask = cv2.inRange(hsv_img, (min_HUE, min_SAT, min_VAL), (max_HUE, max_SAT, max_VAL))\n",
    "H, W = mask.shape\n",
    "\n",
    "# Supressão de ruído\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "mask = cv2.erode(mask, kernel, iterations = 1)\n",
    "\n",
    "# Preenchimento de buracos\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\n",
    "mask = cv2.dilate(mask, kernel, iterations = 3)\n",
    "\n",
    "# Aplicação de máscaras\n",
    "color_img = cv2.bitwise_and(rgb_img, rgb_img, mask=mask)\n",
    "gray_img = cv2.bitwise_and(hsv_img[:,:, 2], hsv_img[:,:, 2], mask=~mask)\n",
    "\n",
    "# O reshape serve apenas pra poder somar as imagens\n",
    "dst_img = gray_img.reshape( ( H, W, 1 ) ) + color_img\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 3, figsize=(16, 10))\n",
    "    \n",
    "# Imagem Original\n",
    "axs[0].imshow(rgb_img, vmin = 0, vmax = 255, cmap=\"gray\")\n",
    "axs[0].set_title(\"Imagem RGB\", fontsize = 16)\n",
    "\n",
    "axs[1].imshow(mask, vmin = 0, vmax = 255, cmap=\"gray\")\n",
    "axs[1].set_title(\"Máscara de Segmentação\", fontsize = 16)\n",
    "\n",
    "axs[2].imshow(dst_img, vmin = 0, vmax = 255, cmap=\"gray\")\n",
    "axs[2].set_title(\"Combinação\", fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2638467b",
   "metadata": {},
   "source": [
    "## <span style='color:green'>Respostas da Questão 5:</span>\n",
    "\n",
    "* (a) Adicione sua resposta aqui.\n",
    "* (b) Adicione sua resposta aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0d0d8",
   "metadata": {},
   "source": [
    " ## <span style='color:blue'>Questão 6: [Valor da Questão: 2.0][Taxa de acerto: x.x]</span>\n",
    "* Carregue a imagem **frutas.jpg** como uma imagem colorida e segmente os elementos pedidos.\n",
    "    * Localize apenas as uvas. \n",
    "    * Localize apenas os kiwis.\n",
    "    * Localize apenas os abacaxis.\n",
    "    * Localize as uvas, kiwis e os abacaxis.\n",
    "    * Localize os morangos e as framboesas.\n",
    "    * Nessa questão não é necessário utilizar morfologia matemática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e63dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_masks(image_rgb, mask):\n",
    "    '''Função para somar as duas máscaras em uma imagem só'''\n",
    "    \n",
    "    image_hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
    "    high, width = mask.shape[0], mask.shape[1]\n",
    "    color_img = cv2.bitwise_and(image_rgb, image_rgb, mask=mask)\n",
    "    gray_img = cv2.bitwise_and(image_hsv[:,:, 2], image_hsv[:,:, 2], mask=~mask)\n",
    "    dst_img = gray_img.reshape( (high, width, 1 ) ) + color_img\n",
    "    \n",
    "    return dst_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_filtering(image_rgb, lower, higher):\n",
    "    '''Aplica a segmentação por cores na imagem'''\n",
    "    \n",
    "    image_hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
    "    mask = cv2.inRange(image_hsv, lower, higher)\n",
    "    dst_img = add_masks(image_rgb, mask)\n",
    "    \n",
    "    return dst_img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTE SEU CÓDIGO AQUI --> QUESTÃO 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uma pequena ajudinha para ajudar na questão acima :)\n",
    "image_rgb = cv2.imread(\"imagens/manopla.jpg\")\n",
    "image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(25, 20))\n",
    "\n",
    "im0, m0 = color_filtering(image_rgb, (0, 75, 75), (20, 255, 255))\n",
    "axs[0,0].imshow(im0, vmin = np.min(im0), vmax = np.max(im0))\n",
    "axs[0,0].set_title(\"Joia da Alma\", fontsize = 25)\n",
    "\n",
    "_, m1_a = color_filtering(image_rgb, (0, 75, 75), (8, 255, 255))\n",
    "_, m1_b = color_filtering(image_rgb, (155, 75, 75), (180, 255, 255))\n",
    "m1 = (m1_a + m1_b)\n",
    "m1[:,400:600] = 0\n",
    "im1 = add_masks(image_rgb, m1)\n",
    "axs[0,1].imshow(im1, vmin = np.min(im1), vmax = np.max(im1))\n",
    "axs[0,1].set_title(\"Joia da Realidade\", fontsize = 25)\n",
    "\n",
    "im2, m2 = color_filtering(image_rgb, (100, 0, 0), (120, 255, 255))\n",
    "axs[0,2].imshow(im2, vmin = np.min(im2), vmax = np.max(im2))\n",
    "axs[0,2].set_title(\"Joia do Espaço\", fontsize = 25)\n",
    "\n",
    "im3, m3 = color_filtering(image_rgb, (155, 75, 75), (160, 255, 255))\n",
    "axs[1,0].imshow(im3, vmin = np.min(im3), vmax = np.max(im3))\n",
    "axs[1,0].set_title(\"Joia do Poder\", fontsize = 25)\n",
    "\n",
    "im4, m4 = color_filtering(image_rgb, (60, 75, 75), (75, 255, 255))\n",
    "axs[1,1].imshow(im4, vmin = np.min(im4), vmax = np.max(im4))\n",
    "axs[1,1].set_title(\"Joia do Tempo\", fontsize = 25)\n",
    "\n",
    "im5, m5 = color_filtering(image_rgb, (22, 125, 125), (32, 255, 255))\n",
    "axs[1,2].imshow(im5, vmin = np.min(im5), vmax = np.max(im5))\n",
    "axs[1,2].set_title(\"Joia da Mente\", fontsize = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb59963",
   "metadata": {},
   "source": [
    "***\n",
    "![image](https://user-images.githubusercontent.com/58775072/156389441-dc11c7ed-4be1-4165-9b7b-30d1f3bf72bb.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
